{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# \n",
    "## Homework Assignment Two ##\n",
    "##     Mollie A. Pepper    ##\n",
    "## Due 04/19/2022 11:59 PM ##\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import make_column_selector as col_selector\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "# import data set\n",
    "data = pd.read_csv('adult_income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
      "       'marital.status', 'occupation', 'relationship', 'race', 'gender',\n",
      "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country',\n",
      "       'income'],\n",
      "      dtype='object')\n",
      "(8739, 15)\n",
      "This data frame has 15 columns and 8739 rows!\n"
     ]
    }
   ],
   "source": [
    "# one\n",
    "print(data.columns)\n",
    "\n",
    "#two\n",
    "rowcol = data.shape\n",
    "print(rowcol)\n",
    "print(\"This data frame has\", rowcol[1], \"columns and\", rowcol[0], \"rows!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education.num     0\n",
      "marital.status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "gender            0\n",
      "capital.gain      0\n",
      "capital.loss      0\n",
      "hours.per.week    0\n",
      "native.country    0\n",
      "income            0\n",
      "dtype: int64\n",
      "Private             5833\n",
      "Self-emp-not-inc     753\n",
      "Local-gov            615\n",
      "?                    490\n",
      "Self-emp-inc         414\n",
      "State-gov            348\n",
      "Federal-gov          283\n",
      "Without-pay            3\n",
      "Name: workclass, dtype: int64\n",
      "Prof-specialty       1360\n",
      "Exec-managerial      1345\n",
      "Craft-repair         1068\n",
      "Sales                1046\n",
      "Adm-clerical          906\n",
      "Other-service         660\n",
      "?                     490\n",
      "Machine-op-inspct     487\n",
      "Transport-moving      412\n",
      "Handlers-cleaners     281\n",
      "Tech-support          253\n",
      "Farming-fishing       235\n",
      "Protective-serv       165\n",
      "Priv-house-serv        28\n",
      "Armed-Forces            3\n",
      "Name: occupation, dtype: int64\n",
      "United-States                 7875\n",
      "?                              170\n",
      "Mexico                         131\n",
      "Canada                          46\n",
      "Philippines                     40\n",
      "Germany                         40\n",
      "India                           32\n",
      "England                         27\n",
      "El-Salvador                     25\n",
      "Cuba                            25\n",
      "Puerto-Rico                     25\n",
      "China                           24\n",
      "South                           20\n",
      "Japan                           20\n",
      "Jamaica                         19\n",
      "Italy                           19\n",
      "Vietnam                         18\n",
      "Iran                            17\n",
      "Poland                          17\n",
      "Taiwan                          16\n",
      "Dominican-Republic              14\n",
      "Guatemala                       13\n",
      "Greece                          12\n",
      "Nicaragua                        9\n",
      "Portugal                         9\n",
      "Cambodia                         8\n",
      "Haiti                            8\n",
      "Columbia                         8\n",
      "Ireland                          7\n",
      "Trinadad&Tobago                  6\n",
      "Ecuador                          6\n",
      "France                           6\n",
      "Peru                             4\n",
      "Hungary                          4\n",
      "Laos                             3\n",
      "Yugoslavia                       3\n",
      "Honduras                         3\n",
      "Outlying-US(Guam-USVI-etc)       3\n",
      "Scotland                         2\n",
      "Hong                             2\n",
      "Thailand                         2\n",
      "Holand-Netherlands               1\n",
      "Name: native.country, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l1map01\\AppData\\Local\\Temp\\ipykernel_27168\\502833839.py:34: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data[\"workclass\"] = data[\"workclass\"].str.replace(\"?\", \"Other\")\n",
      "C:\\Users\\l1map01\\AppData\\Local\\Temp\\ipykernel_27168\\502833839.py:35: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data[\"occupation\"] = data[\"occupation\"].str.replace(\"?\", \"Other\")\n",
      "C:\\Users\\l1map01\\AppData\\Local\\Temp\\ipykernel_27168\\502833839.py:36: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data[\"native.country\"] = data[\"native.country\"].str.replace(\"?\", \"Other\")\n"
     ]
    }
   ],
   "source": [
    "# three\n",
    "\n",
    "#print number of missings per var\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# CHECK FOR ?s\n",
    "#print(data[\"age\"].value_counts())\n",
    "print(data[\"workclass\"].value_counts())\n",
    "#print(data[\"fnlwgt\"].value_counts())\n",
    "#print(data[\"education\"].value_counts())\n",
    "#print(data[\"education.num\"].value_counts())\n",
    "#print(data[\"marital.status\"].value_counts())\n",
    "print(data[\"occupation\"].value_counts())\n",
    "#print(data[\"relationship\"].value_counts())\n",
    "#print(data[\"race\"].value_counts())\n",
    "#print(data[\"gender\"].value_counts())\n",
    "#print(data[\"capital.gain\"].value_counts())\n",
    "#print(data[\"capital.loss\"].value_counts())\n",
    "#print(data[\"hours.per.week\"].value_counts())\n",
    "print(data[\"native.country\"].value_counts())\n",
    "#print(data[\"income\"].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "the following vars have ?s\n",
    "workclass\n",
    "occupation\n",
    "native country\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# replace ?s\n",
    "data[\"workclass\"] = data[\"workclass\"].str.replace(\"?\", \"Other\")\n",
    "data[\"occupation\"] = data[\"occupation\"].str.replace(\"?\", \"Other\")\n",
    "data[\"native.country\"] = data[\"native.country\"].str.replace(\"?\", \"Other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education.num      int64\n",
      "marital.status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "gender            object\n",
      "capital.gain       int64\n",
      "capital.loss       int64\n",
      "hours.per.week     int64\n",
      "native.country    object\n",
      "dtype: object\n",
      "<class 'sklearn.compose._column_transformer.make_column_selector'>\n",
      "[[ 2. 11.  6. ...  4.  0. 39.]\n",
      " [ 3. 11.  6. ...  4.  0. 39.]\n",
      " [ 2. 15.  6. ...  2.  0. 39.]\n",
      " ...\n",
      " [ 2.  9.  6. ...  0.  0. 39.]\n",
      " [ 3.  8.  2. ...  4.  1. 39.]\n",
      " [ 3.  9.  4. ...  4.  1. 39.]]\n"
     ]
    }
   ],
   "source": [
    "# four\n",
    "\n",
    "data_y = data[\"income\"]\n",
    "data = data.drop([\"income\"], axis=1)\n",
    "data_1 = data.copy(deep=True)\n",
    "\n",
    "print(data.dtypes)\n",
    "#print(data.head)\n",
    "\n",
    "\n",
    "# select categorical data\n",
    "categorical_cols_obj = col_selector(dtype_include=object)\n",
    "print(type(categorical_cols_obj))\n",
    "categorical_features = categorical_cols_obj(data)\n",
    "# select numeric data\n",
    "int_cols_obj = col_selector(dtype_include=\"int64\")\n",
    "numeric_features = int_cols_obj(data)\n",
    "\n",
    "#transform and combine\n",
    "df_cat = data[categorical_features]\n",
    "ob_encoded = preprocessing.OrdinalEncoder()\n",
    "cat_encoded = ob_encoded.fit_transform(df_cat)\n",
    "print(cat_encoded)\n",
    "\n",
    "\n",
    "X = np.hstack([cat_encoded, np.array(data[numeric_features])])\n",
    "\n",
    "#print(x.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.807\n"
     ]
    }
   ],
   "source": [
    "# five\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "x = data\n",
    "\n",
    "yb = preprocessing.LabelEncoder()\n",
    "y = yb.fit_transform(data_y)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "               transformers=[\n",
    "               ('num', StandardScaler(), numeric_features),\n",
    "               ('cat', OrdinalEncoder(), categorical_features)])\n",
    "\n",
    "clf = make_pipeline(preprocessor, LogisticRegression(max_iter=500))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy is: 85.1258581235698\n",
      "Random Forest accuracy is: 87.24256292906179\n",
      "Naive Bayes accuracy: 80.94965675057209\n"
     ]
    }
   ],
   "source": [
    "# six\n",
    "xdr_train, xdr_test, ydr_train, ydr_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "\"\"\"\n",
    "Decision Tree\n",
    "\"\"\"\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(xdr_train,ydr_train)   \n",
    "\n",
    "predict=dtree.predict(xdr_test) # predicted y from the x test                              \n",
    "predict\n",
    "\n",
    "print(\"Decision Tree accuracy is:\", accuracy_score(ydr_test, predict)*100)\n",
    "\n",
    "\"\"\"\n",
    "Random Forest\n",
    "\"\"\"\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(xdr_train, ydr_train)\n",
    "\n",
    "rfc_predict = rfc.predict(xdr_test)  \n",
    "print(\"Random Forest accuracy is:\", accuracy_score(ydr_test,rfc_predict)*100)    \n",
    "\n",
    "\"\"\"\n",
    "Naive Bayes\n",
    "\"\"\"\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(x_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(x_test)\n",
    "\n",
    "print(\"Naive Bayes accuracy:\", metrics.accuracy_score(y_test, y_pred)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe results above show that while all three classifiers are above 80% accuracy,\\nrandom forest and decision tree are quite a bit more accurate than the naive bayes method.\\nOverall, a random forest classifier would be the best choice for this model.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seven\n",
    "\n",
    "\"\"\"\n",
    "The results above show that while all three classifiers are above 80% accuracy,\n",
    "random forest and decision tree are quite a bit more accurate than the naive bayes method.\n",
    "Overall, a random forest classifier would be the best choice for this model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSummary/Conclusion:\\nIn the categorical_cols_conversion file we learned how to transform categorical variables into numeric values so that they can be used in our models. \\nThere are two main types of encoding that we discussed: ordinal and one-hot. One hot creates one variable for each distinct category, assigning it a value \\nof one when the observation has that value and zero otherwise. Ordinal assigns an integer value to each distinct category. \\n\\nTo do this, one needs to check for missing values in the dataset, and then remove the target variable from the data frame. \\nNext, split the remainder of the dataset based on whether the variable is numeric or categorical. \\nThere are different ways to perform encoding. Firstly, we can create an ordinal encoder object and use fit_transform to create an encoded version of the categorical variables. \\nThen the encoded categorical variables can be appended to the numerical variables. This method does not standardize the numeric variables though; one way to resolve this is to \\ninstead use cat.codes for the categorical subset and standard scaler to standardize the numerical subset. This can all be done in one step by using the ColumnTransformer \\nfunction. We also discussed using pipelines to build models.\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Summary/Conclusion:\n",
    "In the categorical_cols_conversion file we learned how to transform categorical variables into numeric values so that they can be used in our models. \n",
    "There are two main types of encoding that we discussed: ordinal and one-hot. One hot creates one variable for each distinct category, assigning it a value \n",
    "of one when the observation has that value and zero otherwise. Ordinal assigns an integer value to each distinct category. \n",
    "\n",
    "To do this, one needs to check for missing values in the dataset, and then remove the target variable from the data frame. \n",
    "Next, split the remainder of the dataset based on whether the variable is numeric or categorical. \n",
    "There are different ways to perform encoding. Firstly, we can create an ordinal encoder object and use fit_transform to create an encoded version of the categorical variables. \n",
    "Then the encoded categorical variables can be appended to the numerical variables. This method does not standardize the numeric variables though; one way to resolve this is to \n",
    "instead use cat.codes for the categorical subset and standard scaler to standardize the numerical subset. This can all be done in one step by using the ColumnTransformer \n",
    "function. We also discussed using pipelines to build models.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
